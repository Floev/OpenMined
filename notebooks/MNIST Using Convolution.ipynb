{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Using convolution\n",
    "\n",
    "This is a stipped down version of MNIST.  We will learn how to recognize a 6!\n",
    "\n",
    "For this demo to work you'll need to download the mnist dataset from [here](http://yann.lecun.com/exdb/mnist/)\n",
    "and place them in `notebooks/data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function to read the MNIST data set\n",
    "\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Loosely inspired by http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "which is GPL licensed.\n",
    "\"\"\"\n",
    "\n",
    "def read(dataset = 'training', path = './data', seperator = '-'):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is 'training':\n",
    "        fname_img = os.path.join(path, 'train-images'+seperator+'idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels'+seperator+'idx1-ubyte')\n",
    "    elif dataset is 'testing':\n",
    "        fname_img = os.path.join(path, 't10k-images'+seperator+'idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels'+seperator+'idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        tmp = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "        tmp2 = np.array(tmp).astype('float')\n",
    "        img = [ x / 255 for x in tmp2 ]\n",
    "        \n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_img(i)\n",
    "\n",
    "def show(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train and get really good at recognizing this 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ea2757e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = read('training','data','.')\n",
    "#mnist = read('training')\n",
    "mnist = list(mnist)\n",
    "label, pixels = mnist[32] ## random 6 i found\n",
    "show(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(label,nb_labels=10):\n",
    "    out = np.zeros(nb_labels)\n",
    "    out[label-1]=1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 15\n",
    "pics = [x[1]for x in mnist[:samples]]\n",
    "labels = [onehot(x[0]) for x in mnist[:samples]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openmined imports:\n",
    "import syft\n",
    "import syft.nn as nn\n",
    "import syft.controller\n",
    "import imp\n",
    "imp.reload(syft.controller)\n",
    "imp.reload(syft.nn)\n",
    "imp.reload(syft)\n",
    "from syft import FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([15, 28, 28], [15, 10], [28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = FloatTensor(pics,autograd=True)\n",
    "target = FloatTensor(labels).autograd(True)\n",
    "pic_size = data.shape()[1:3]\n",
    "data.shape(),target.shape(),pic_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add(nn.View(samples,1,pic_size[0],pic_size[1]))\n",
    "model.add(nn.Conv2d(1,1,7))\n",
    "model.add(nn.Sigmoid())\n",
    "model.add(nn.Conv2d(1,1,7))\n",
    "model.add(nn.Sigmoid())\n",
    "model.add(nn.View(samples,16*16))\n",
    "model.add(nn.Linear(16*16,25))\n",
    "model.add(nn.Sigmoid())\n",
    "model.add(nn.Linear(5*5,10))\n",
    "model.add(nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([15, 10], [15, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre-training\n",
    "pred = model(data)\n",
    "pred.shape(),target.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our model to become a pro at that digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.6375493785\n",
      "15.0665049064\n",
      "14.9749110703\n",
      "14.9965804033\n",
      "14.9993906205\n",
      "14.9998584273\n",
      "14.9999621704\n",
      "14.9999892075\n",
      "6.79 s ± 198 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit #-n 3\n",
    "\n",
    "pred = model(data)\n",
    "loss = (pred - target) ** 2 # Mean Squared Error Loss\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "for i,p in enumerate(model.parameters()):\n",
    "    if p.autograd():\n",
    "        p -= p.grad()\n",
    "\n",
    "print(loss.to_numpy().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.6686268 ,  0.2665654 ,  0.9498549 ,  0.268577  ,  0.616451  ,\n",
       "         0.9752122 ,  0.8174934 ,  0.4225313 ,  0.7959878 ,  0.05409032]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 1\n",
    "pred.to_numpy()[example],target.to_numpy()[example]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find a different 6 in the data and see how well we can recognize that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfiApwg8kRfiBpAg/kBThB5L6P7rEwt5mBzUJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ea4818128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "other_label, other_pixels = mnist[36] ## a different random 6 i found\n",
    "show(other_pixels)\n",
    "other_six = FloatTensor(other_pixels).view(1, 28,28).autograd(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this doesn't work yet, need batch support\n",
    "pred = model(other_six)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the 6th element of the array!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openmined imports:\n",
    "import syft\n",
    "import syft.nn as nn\n",
    "import syft.controller\n",
    "import imp\n",
    "imp.reload(syft.controller)\n",
    "imp.reload(syft.nn)\n",
    "imp.reload(syft)\n",
    "from syft import FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[[[ 0.9993694  0.5485256]]]]\n",
       " [syft.FloatTensor:579 grad:None size:1x1x1x2]\n",
       " \n",
       " \t-----------creators-----------\n",
       " \t[syft.FloatTensor:571 grad:None size:1x1x2x2]\n",
       " \t[syft.FloatTensor:577 grad:None size:1x2x1]\n",
       " \t[syft.FloatTensor:578 grad:None size:1]\n",
       " \t[syft.FloatTensor:573 grad:None size:2]\n",
       " \t[syft.FloatTensor:574 grad:None size:2]\n",
       " \t[syft.FloatTensor:575 grad:None size:2]\n",
       " \t[syft.FloatTensor:576 grad:None size:1]\n",
       " \t------------------------------\n",
       " \n",
       " , [[[[ 2.  1.]]]]\n",
       " [syft.FloatTensor:572 grad:None size:1x1x1x2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = FloatTensor( [[[[1,0],[0,1]]]],autograd=1)\n",
    "target = FloatTensor( [[[[2,1]]]],autograd=1)\n",
    "model = nn.Conv2d(1,1,(2,1))\n",
    "model(data),target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[[[ 0.9993694   0.5485256 ]\n",
       "    [-0.07908762  0.3619677 ]]]]\n",
       " [syft.FloatTensor:606 grad:None size:1x1x2x2]\n",
       " \n",
       " \t-----------creators-----------\n",
       " \t[syft.FloatTensor:598 grad:None size:1x1x3x3]\n",
       " \t[syft.FloatTensor:604 grad:None size:1x2x2]\n",
       " \t[syft.FloatTensor:605 grad:None size:1]\n",
       " \t[syft.FloatTensor:600 grad:None size:2]\n",
       " \t[syft.FloatTensor:601 grad:None size:2]\n",
       " \t[syft.FloatTensor:602 grad:None size:2]\n",
       " \t[syft.FloatTensor:603 grad:None size:1]\n",
       " \t------------------------------\n",
       " \n",
       " , [[[[ 1.  2.]\n",
       "    [ 1.  0.]]]]\n",
       " [syft.FloatTensor:599 grad:None size:1x1x2x2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = FloatTensor( [[[[1,0,1],[0,0,0],[0,1,0]]]],autograd=1)\n",
    "target = FloatTensor( [[[[1,2],[1,0]]]],autograd=1)\n",
    "model = nn.Conv2d(1,1,2)\n",
    "model(data),target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[ 0.9993694   0.5485256 ]\n",
       "   [ 0.3619677  -0.07908762]]]\n",
       " [syft.FloatTensor:604 grad:None size:1x2x2]\n",
       " \n",
       " \t-----------children-----------\n",
       " \t[syft.FloatTensor:606 grad:None size:1x1x2x2]\n",
       " \t------------------------------\n",
       " \n",
       " , [ 0.]\n",
       " [syft.FloatTensor:605 grad:None size:1], [ 1.  1.]\n",
       " [syft.FloatTensor:600 grad:None size:2], [ 0.  0.]\n",
       " [syft.FloatTensor:601 grad:None size:2], [ 1.  1.]\n",
       " [syft.FloatTensor:602 grad:None size:2], [ 1.]\n",
       " [syft.FloatTensor:603 grad:None size:1]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 2] [1, 1, 2, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[[ 1.  1.]\n",
       "   [ 1.  1.]]]]\n",
       "[syft.FloatTensor:643 grad:None size:1x1x2x2]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(data)\n",
    "print(pred.shape(),target.shape())\n",
    "loss = (pred - target)# ** 2 # Mean Squared Error Loss\n",
    "loss.backward()\n",
    "loss.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[[[ -6.30617100e-04  -1.45147400e+00]\n",
       "    [ -1.07908800e+00   3.61967700e-01]]]]\n",
       " [syft.FloatTensor:642 grad:643 size:1x1x2x2]\n",
       " \n",
       " \t-----------creators-----------\n",
       " \t[syft.FloatTensor:639 grad:644 size:1x1x2x2]\n",
       " \t[syft.FloatTensor:599 grad:652 size:1x1x2x2]\n",
       " \t------------------------------\n",
       " \n",
       " , [[[ 0.9993694   0.5485256 ]\n",
       "   [ 0.3619677  -0.07908762]]]\n",
       " [syft.FloatTensor:604 grad:651 size:1x2x2]\n",
       " \n",
       " \t-----------children-----------\n",
       " \t[syft.FloatTensor:606 grad:None size:1x1x2x2]\n",
       " [syft.FloatTensor:639 grad:644 size:1x1x2x2]\n",
       " \t------------------------------\n",
       " \n",
       " , [[[ 1.  1.]\n",
       "   [ 1.  1.]]]\n",
       " [syft.FloatTensor:651 grad:None size:1x2x2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,model.parameters()[0],model.parameters()[0].grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[ 1.  1.]\n",
       "  [ 1.  1.]]]\n",
       "[syft.FloatTensor:651 grad:None size:1x2x2]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad()\n",
    "model.parameters()[0].grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#above, I would like to see the backpropped error, not a backprop of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.9987388 -1.902949 ]\n",
      "  [ 1.723935  -1.158175 ]]]\n",
      "[[[[  3.97678000e-07   2.10677800e+00]\n",
      "   [  1.16443000e+00   1.31020600e-01]]]]\n",
      "[[[ 0.9775027 -4.767838 ]\n",
      "  [ 2.413392  -3.293187 ]]]\n",
      "[[[[  1.12742600e-04   2.05189800e+00]\n",
      "   [  1.13956900e+00   1.18837600e-01]]]]\n",
      "[[[ 0.9367166 -7.537372 ]\n",
      "  [ 3.054581  -5.362335 ]]]\n",
      "[[[[  4.15877400e-04   1.91757800e+00]\n",
      "   [  1.07034300e+00   1.02780800e-01]]]]\n",
      "[[[  0.8771961 -10.15616  ]\n",
      "  [  3.634678   -7.324236 ]]]\n",
      "[[[[  8.85672000e-04   1.71450900e+00]\n",
      "   [  9.62264200e-01   8.41281900e-02]]]]\n",
      "[[[  0.8001317 -12.57182  ]\n",
      "  [  4.142082   -9.139653 ]]]\n",
      "[[[[ 0.00148473  1.458856  ]\n",
      "   [ 0.8239343   0.0643646 ]]]]\n",
      "[[[  0.7070646 -14.73605  ]\n",
      "  [  4.566644  -10.77228  ]]]\n",
      "[[[[ 0.00216537  1.170969  ]\n",
      "   [ 0.6663648   0.04506322]]]]\n",
      "[[[  0.5998563 -16.60555  ]\n",
      "  [  4.899873  -12.18946  ]]]\n",
      "[[[[ 0.00287341  0.8737624 ]\n",
      "   [ 0.5020983   0.02776041]]]]\n",
      "[[[  0.4806508 -18.14294  ]\n",
      "  [  5.135104  -13.36284  ]]]\n",
      "[[[[ 0.00355249  0.5908951 ]\n",
      "   [ 0.3442104   0.01383348]]]]\n",
      "[[[  0.3518323 -19.31748  ]\n",
      "  [  5.267634  -14.26898  ]]]\n",
      "[[[[ 0.00414855  0.3448833 ]\n",
      "   [ 0.2052688   0.00439102]]]]\n",
      "[[[  0.2159771 -20.10567  ]\n",
      "  [  5.294811  -14.88973  ]]]\n",
      "[[[[ 0.00461416  0.1553091 ]\n",
      "   [ 0.0963334   0.00018465]]]]\n",
      "[[[  0.07580233 -20.49174   ]\n",
      "  [  5.216092   -15.21269   ]]]\n",
      "[[[[ 0.00491224  0.03726297]\n",
      "   [ 0.02607545  0.00154918]]]]\n",
      "[[[ -0.06588852 -20.46798   ]\n",
      "  [  5.033051   -15.23139   ]]]\n",
      "[[[[  5.01907400e-03   1.41160900e-04]\n",
      "   [  8.74615500e-05   8.37601600e-03]]]]\n",
      "[[[ -0.2062616 -20.03485  ]\n",
      "  [  4.749348  -14.94547  ]]]\n",
      "[[[[ 0.00492615  0.0468986 ]\n",
      "   [ 0.02043809  0.02012173]]]]\n",
      "[[[ -0.3425095 -19.20104  ]\n",
      "  [  4.370659  -14.36063  ]]]\n",
      "[[[[ 0.00464087  0.1738135 ]\n",
      "   [ 0.08550745  0.03585136]]]]\n",
      "[[[ -0.4719071 -17.9832   ]\n",
      "  [  3.904557  -13.48859  ]]]\n",
      "[[[[ 0.00418594  0.3707834 ]\n",
      "   [ 0.1901159   0.05431284]]]]\n",
      "[[[ -0.5918666 -16.40569  ]\n",
      "  [  3.360363  -12.34677  ]]]\n",
      "[[[[ 0.00359757  0.6221294 ]\n",
      "   [ 0.3259369   0.07403663]]]]\n",
      "[[[ -0.6999887 -14.50008  ]\n",
      "  [  2.748962  -10.95802  ]]]\n",
      "[[[[ 0.0029226   0.9078447 ]\n",
      "   [ 0.4821587   0.09345271]]]]\n",
      "[[[ -0.794111 -12.30446 ]\n",
      "  [  2.082582  -9.350105]]]\n",
      "[[[[ 0.00221475  1.205186  ]\n",
      "   [ 0.6463463   0.1110156 ]]]]\n",
      "[[[-0.8723511 -9.862749 ]\n",
      "  [ 1.374551  -7.55519  ]]]\n",
      "[[[[ 0.00153038  1.490485  ]\n",
      "   [ 0.8054304   0.1253272 ]]]]\n",
      "[[[-0.9331441 -7.223786 ]\n",
      "  [ 0.6390281 -5.609171 ]]]\n",
      "[[[[  9.23948500e-04   1.74103200e+00]\n",
      "   [  9.46747700e-01   1.35248400e-01]]]]\n",
      "[[[-0.9752742 -4.440347 ]\n",
      "  [-0.1092751 -3.550968 ]]]\n",
      "[[[[  4.43736600e-04   1.93688300e+00]\n",
      "   [  1.05905000e+00   1.39989400e-01]]]]\n",
      "434 ms ± 3.73 ms per loop (mean ± std. dev. of 7 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3\n",
    "\n",
    "pred = model(data)\n",
    "loss = (pred - target) ** 2 # Mean Squared Error Loss\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "for i,p in enumerate(model.parameters()):\n",
    "    if p.autograd():\n",
    "        print( p.grad().to_numpy())\n",
    "        p -= p.grad()*0.01\n",
    "\n",
    "#print(loss.to_numpy().sum())\n",
    "print(loss.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
