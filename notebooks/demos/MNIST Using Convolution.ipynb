{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Using convolution\n",
    "\n",
    "This is a stipped down version of MNIST.  We will learn how to recognize a 6!\n",
    "\n",
    "For this demo to work you'll need to download the mnist dataset from [here](http://yann.lecun.com/exdb/mnist/)\n",
    "and place them in `notebooks/data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function to read the MNIST data set\n",
    "\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Loosely inspired by http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "which is GPL licensed.\n",
    "\"\"\"\n",
    "\n",
    "def read(dataset = 'training', path = './data', seperator = '-'):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is 'training':\n",
    "        fname_img = os.path.join(path, 'train-images'+seperator+'idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels'+seperator+'idx1-ubyte')\n",
    "    elif dataset is 'testing':\n",
    "        fname_img = os.path.join(path, 't10k-images'+seperator+'idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels'+seperator+'idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        tmp = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "        tmp2 = np.array(tmp).astype('float')\n",
    "        img = [ x / 255 for x in tmp2 ]\n",
    "        \n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_img(i)\n",
    "\n",
    "def show(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train and get really good at recognizing this 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = read('training','..\\\\data','.')\n",
    "#mnist = read('training')\n",
    "mnist = list(mnist)\n",
    "label, pixels = mnist[32] ## random 6 i found\n",
    "show(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(label,nb_labels=10):\n",
    "    out = np.zeros(nb_labels)\n",
    "    out[label-1]=1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 15\n",
    "pics = [x[1]for x in mnist[:samples]]\n",
    "labels = [onehot(x[0]) for x in mnist[:samples]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openmined imports:\n",
    "import syft\n",
    "import syft.nn as nn\n",
    "import syft.controller\n",
    "import imp\n",
    "imp.reload(syft.controller)\n",
    "imp.reload(syft.nn)\n",
    "imp.reload(syft)\n",
    "from syft import FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FloatTensor(pics,autograd=True)\n",
    "target = FloatTensor(labels).autograd(True)\n",
    "pic_size = data.shape()[1:3]\n",
    "data.shape(),target.shape(),pic_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tester(*out_dims,id=None):\n",
    "    x = list( out_dims)\n",
    "    print(x,type(x))\n",
    "    y = [1,2,3]\n",
    "    print(y,type(y))\n",
    "tester(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add(nn.View(samples,1,pic_size[0],pic_size[1]))\n",
    "model.add(nn.Conv2d(1,1,7))\n",
    "model.add(nn.Sigmoid())\n",
    "model.add(nn.Conv2d(1,1,7))\n",
    "model.add(nn.Sigmoid())\n",
    "model.add(nn.View(samples,16*16))\n",
    "model.add(nn.Linear(16*16,25))\n",
    "model.add(nn.Sigmoid())\n",
    "model.add(nn.Linear(5*5,10))\n",
    "model.add(nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-training\n",
    "pred = model(data)\n",
    "pred.shape(),target.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our model to become a pro at that digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit #-n 3\n",
    "\n",
    "pred = model(data)\n",
    "loss = (pred - target) ** 2 # Mean Squared Error Loss\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "for i,p in enumerate(model.parameters()):\n",
    "    if p.autograd():\n",
    "        p -= p.grad()\n",
    "\n",
    "print(loss.to_numpy().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = 1\n",
    "pred.to_numpy()[example],target.to_numpy()[example]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find a different 6 in the data and see how well we can recognize that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_label, other_pixels = mnist[36] ## a different random 6 i found\n",
    "show(other_pixels)\n",
    "other_six = FloatTensor(other_pixels).view(1, 28,28).autograd(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this doesn't work yet, need batch support\n",
    "pred = model(other_six)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the 6th element of the array!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openmined imports:\n",
    "import syft\n",
    "import syft.nn as nn\n",
    "import syft.controller\n",
    "import imp\n",
    "imp.reload(syft.controller)\n",
    "imp.reload(syft.nn)\n",
    "imp.reload(syft)\n",
    "from syft import FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FloatTensor( [[[[1,0],[0,1]]]],autograd=1)\n",
    "target = FloatTensor( [[[[2,1]]]],autograd=1)\n",
    "model = nn.Conv2d(1,1,(2,1))\n",
    "model(data),target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FloatTensor( [[[[1,0,1],[0,0,0],[0,1,0]]]],autograd=1)\n",
    "target = FloatTensor( [[[[1,2],[1,0]]]],autograd=1)\n",
    "model = nn.Conv2d(1,1,2)\n",
    "model(data),target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grad = FloatTensor(-loss.to_numpy(),autograd=1)\n",
    "\n",
    "loss#.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(data)\n",
    "print(pred.shape(),target.shape())\n",
    "loss = (pred - target)# ** 2 # Mean Squared Error Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.id,pred.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.autograd(),loss.autograd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.to_numpy()\n",
    "loss.backward()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(data)\n",
    "print(pred.shape(),target.shape())\n",
    "loss = (pred - target)# ** 2 # Mean Squared Error Loss\n",
    "grad = FloatTensor(-loss.to_numpy(),autograd=1)\n",
    "loss.backward(grad)\n",
    "loss.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad.id,loss.id,grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(data)\n",
    "print(pred.shape(),target.shape())\n",
    "loss = (pred - target)# ** 2 # Mean Squared Error Loss\n",
    "loss1 = FloatTensor(-loss.to_numpy())\n",
    "loss.backward(loss1)\n",
    "loss.grad(),model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(data)\n",
    "print(pred.shape(),target.shape())\n",
    "loss = (pred - target)# ** 2 # Mean Squared Error Loss\n",
    "loss.backward()\n",
    "loss.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,model.parameters()[0],model.parameters()[0].grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.grad()\n",
    "#model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#above, I would like to see the backpropped error, not a backprop of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 3\n",
    "\n",
    "pred = model(data)\n",
    "loss = (pred - target) ** 2 # Mean Squared Error Loss\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "for i,p in enumerate(model.parameters()):\n",
    "    if p.autograd():\n",
    "        print( p.grad().to_numpy())\n",
    "        p -= p.grad()*0.01\n",
    "\n",
    "#print(loss.to_numpy().sum())\n",
    "print(loss.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
